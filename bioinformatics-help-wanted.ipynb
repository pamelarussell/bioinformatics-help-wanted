{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics help wanted: find open source repos seeking contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook searches the GitHub API for repositories matching search terms, and for open issues within those repositories matching an issue label. For example, use this code to find a list of all repositories matching the search term \"bioinformatics\", written in languages of your choice, with issues labeled \"help wanted\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing requirements\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "#### GitHub credentials\n",
    "A GitHub account and associated OAuth token are required to run this notebook. See these [instructions](https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line) to create a token.\n",
    "\n",
    "#### GitHub search terms\n",
    "Simply modify the \"Parameters\" section with your GitHub credentials and desired search terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub credentials\n",
    "gh_username = 'pamelarussell'\n",
    "gh_oauth_file = 'gh_oauth_token.txt'\n",
    "\n",
    "# GitHub search terms\n",
    "topics = ['bioinformatics']\n",
    "languages = ['scala', 'java']\n",
    "issue_label = 'help wanted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "import json\n",
    "import pycurl\n",
    "\n",
    "from time import sleep\n",
    "from github3 import login\n",
    "from pycurl import Curl\n",
    "from io import BytesIO\n",
    "from json.decoder import JSONDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gh_oauth_file) as fh:\n",
    "    gh_oauth_key = fh.readline().strip()\n",
    "api_rate_limit_per_hour = 5000\n",
    "sec_between_requests = 60 * 60 / api_rate_limit_per_hour\n",
    "url_repos = 'https://api.github.com/repos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for GitHub API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gh_userpwd(gh_username, gh_oauth_key):\n",
    "    \"\"\" Returns string version of GitHub credentials to be passed to GitHub API\"\"\"\n",
    "    return('{}:{}'.format(gh_username, gh_oauth_key))\n",
    "\n",
    "def sleep_gh_rate_limit():\n",
    "    \"\"\"Sleep for the required amount of time per API request to ensure rate limit is not exceeded\"\"\"    \n",
    "    sleep(sec_between_requests + 0.01) \n",
    "    \n",
    "def add_page_num(url, page_num):\n",
    "    \"\"\"Add page number to GitHub API request and return new URL\"\"\"\n",
    "    if '?' in url:\n",
    "        return '{}&page={}'.format(url, page_num)\n",
    "    else:\n",
    "        return '{}?page={}'.format(url, page_num)\n",
    "    \n",
    "def validate_response_found(parsed, message = ''):\n",
    "    \"\"\" Check that the GitHub API returned a valid response\n",
    "    \n",
    "    Args:\n",
    "        parsed: dict\n",
    "            Parsed JSON response\n",
    "        message\n",
    "            Extra info to print\n",
    "    \"\"\"\n",
    "    if 'message' in parsed:\n",
    "        if parsed['message'] == 'Not Found':\n",
    "            raise ValueError('Parsed response has message: Not Found. Further information:\\n{}'.format(message))\n",
    "\n",
    "def gh_curl_response(url, gh_username, gh_oauth_key):\n",
    "    \"\"\"Returns the parsed curl response from the GitHub API; combines pages if applicable\n",
    "    \n",
    "    Returns:\n",
    "        Parsed API response consisting of a list of dicts, one for each record, or just one\n",
    "        dict if the response was a single dict.\n",
    "        \n",
    "    \"\"\"\n",
    "    page_num = 1\n",
    "    results = []\n",
    "    prev_response = None\n",
    "    while True:\n",
    "        buffer = BytesIO()\n",
    "        c = pycurl.Curl()\n",
    "        c.setopt(c.URL, add_page_num(url, page_num))\n",
    "        c.setopt(c.USERPWD, gh_userpwd(gh_username, gh_oauth_key))\n",
    "        c.setopt(c.WRITEDATA, buffer)\n",
    "        sleep_gh_rate_limit()\n",
    "        try:\n",
    "            c.perform()\n",
    "        except pycurl.error as e:\n",
    "            print(url)\n",
    "            raise e\n",
    "        c.close()\n",
    "        body = buffer.getvalue()\n",
    "        try:\n",
    "            parsed = json.loads(body.decode())\n",
    "            if 'message' in parsed:\n",
    "                if 'API rate limit exceeded' in parsed['message']:\n",
    "                    raise PermissionError(parsed['message'])\n",
    "        except JSONDecodeError:\n",
    "            print('Caught JSONDecodeError. Returning empty list for URL {}'.format(url))\n",
    "            return []\n",
    "        validate_response_found(parsed, add_page_num(url, page_num))\n",
    "        if type(parsed) is dict:\n",
    "            return parsed\n",
    "        else:\n",
    "            if len(parsed) == 0:\n",
    "                break\n",
    "            else:\n",
    "                if parsed == prev_response:\n",
    "                    # Sometimes GitHub API will return the same response for any provided page num\n",
    "                    break\n",
    "                else:\n",
    "                    prev_response = parsed\n",
    "                    results = results + parsed\n",
    "                    page_num = page_num + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Repo: hail-is/hail\n",
      "Description: Scalable genomic data analysis.\n",
      "Language: Scala\n",
      "URL: https://github.com/hail-is/hail\n",
      "Open issues with label \"help wanted\":\n",
      "\t- Improve nCubeOfVolumeAtMost (https://github.com/hail-is/hail/issues/1998)\n",
      "\t- Hail's Matrix Multiply Should Perform Better When Massively Reducing Size (https://github.com/hail-is/hail/issues/1975)\n",
      "\n",
      "\n",
      "Repo: biojava/biojava\n",
      "Description: :book::microscope::coffee: BioJava is an open-source project dedicated to providing a Java library for processing biological data.\n",
      "Language: Java\n",
      "URL: https://github.com/biojava/biojava\n",
      "Open issues with label \"help wanted\":\n",
      "\t- Extend dssp implementation to also support the promotif standard (https://github.com/biojava/biojava/issues/764)\n",
      "\t- Use Protonation Variants Companion Dictionary (https://github.com/biojava/biojava/issues/686)\n",
      "\t- Secondary structure assignment could be done taking all symmetry partners into account (https://github.com/biojava/biojava/issues/454)\n",
      "\t- Add Bird parsing functionality (https://github.com/biojava/biojava/issues/436)\n",
      "\t- Add support for parsing secondary structure in mmCIFF (https://github.com/biojava/biojava/issues/333)\n",
      "\t- New StructuralAlignment Algorithms (https://github.com/biojava/biojava/issues/307)\n",
      "\t- Introduction of semiglobal alignments (https://github.com/biojava/biojava/issues/243)\n",
      "\t- Add ability to create a Profile from a multiple sequence alignment file  (https://github.com/biojava/biojava/issues/223)\n",
      "\t- MrBayes Parser (https://github.com/biojava/biojava/issues/123)\n",
      "\t- Balibase (https://github.com/biojava/biojava/issues/119)\n",
      "\t- Add a SCOP2 parser (https://github.com/biojava/biojava/issues/82)\n",
      "\n",
      "\n",
      "Repo: openwdl/wdl\n",
      "Description: Workflow Description Language - Specification and Implementations\n",
      "Language: Java\n",
      "URL: https://github.com/openwdl/wdl\n",
      "Open issues with label \"help wanted\":\n",
      "\t- map contains_key() function (https://github.com/openwdl/wdl/issues/305)\n",
      "\t- Allow passthrough of inputs from the `inputs.json` to a subworkflow (https://github.com/openwdl/wdl/issues/262)\n",
      "\n",
      "\n",
      "Repo: intermine/intermine\n",
      "Description: A powerful open source data warehouse system\n",
      "Language: Java\n",
      "URL: https://github.com/intermine/intermine\n",
      "Open issues with label \"help wanted\":\n",
      "\t- Investigate code coverage solutions (https://github.com/intermine/intermine/issues/1991)\n",
      "\t- Error in Python code generated on Flymine website while accessing templates. (https://github.com/intermine/intermine/issues/1981)\n",
      "\t- Gradle 4.1 is to old for Java 11 (https://github.com/intermine/intermine/issues/1915)\n",
      "\t- old JSON jar is only used once. Can we replace? (https://github.com/intermine/intermine/issues/1845)\n",
      "\t- when trying to create a list with the same name as another list via api, give informative error (https://github.com/intermine/intermine/issues/1835)\n",
      "\t- InterMineR - add R to code generation and API tab (https://github.com/intermine/intermine/issues/1782)\n",
      "\t- Code generation for JS is out of date  (https://github.com/intermine/intermine/issues/1775)\n",
      "\t- Generated Python Code for Query - show comments hides first line (https://github.com/intermine/intermine/issues/1659)\n",
      "\n",
      "\n",
      "Repo: fulcrumgenomics/fgbio\n",
      "Description: Tools for working with genomic and high throughput sequencing data.\n",
      "Language: Scala\n",
      "URL: https://github.com/fulcrumgenomics/fgbio\n",
      "Open issues with label \"help wanted\":\n",
      "\t- Support single-end reads in GroupReadsByUmi  (https://github.com/fulcrumgenomics/fgbio/issues/287)\n",
      "\t- A tool that can downsample a BAM many times (https://github.com/fulcrumgenomics/fgbio/issues/232)\n",
      "\n",
      "\n",
      "Repo: compomics/peptide-shaker\n",
      "Description: Interpretation of proteomics identification results\n",
      "Language: Java\n",
      "URL: https://github.com/compomics/peptide-shaker\n",
      "Open issues with label \"help wanted\":\n",
      "\t- export report in GUI (https://github.com/compomics/peptide-shaker/issues/371)\n",
      "\t- Andromeda Error (https://github.com/compomics/peptide-shaker/issues/368)\n",
      "\t- Memory issue with Peptide Shaker 1.16.42 (https://github.com/compomics/peptide-shaker/issues/367)\n",
      "\t- Transcriptome validation (https://github.com/compomics/peptide-shaker/issues/363)\n",
      "\t- How to incorporate/merge peptide-shaker outputs of peptides and proteins (https://github.com/compomics/peptide-shaker/issues/361)\n",
      "\t- peptide shaker error (https://github.com/compomics/peptide-shaker/issues/342)\n",
      "\t- Progenesis LC-MS export (https://github.com/compomics/peptide-shaker/issues/340)\n",
      "\t- PeptideShaker runs out of memory (https://github.com/compomics/peptide-shaker/issues/282)\n",
      "\t- Morpheus/MetaMorpheus mzIdent input trouble (https://github.com/compomics/peptide-shaker/issues/276)\n",
      "\t- selenocysteine analysis (https://github.com/compomics/peptide-shaker/issues/255)\n",
      "\t- PS excluding 40% or more of peptides from tandem search (https://github.com/compomics/peptide-shaker/issues/239)\n",
      "\t- Validating and exporting PSM from Mascot dat at 1% FDR (https://github.com/compomics/peptide-shaker/issues/230)\n",
      "\n",
      "\n",
      "Repo: proteinevolution/Toolkit\n",
      "Description: The MPI Bioinformatics Toolkit\n",
      "Language: Scala\n",
      "URL: https://github.com/proteinevolution/Toolkit\n",
      "Open issues with label \"help wanted\":\n",
      "\t- all scripts should be part of the repo (https://github.com/proteinevolution/Toolkit/issues/823)\n",
      "\t- helper scripts and bioprogs (https://github.com/proteinevolution/Toolkit/issues/295)\n",
      "\t- Create mock biodbs (https://github.com/proteinevolution/Toolkit/issues/247)\n",
      "\n",
      "\n",
      "Repo: compomics/compomics-utilities\n",
      "Description: Open source Java library for computational proteomics\n",
      "Language: Java\n",
      "URL: https://github.com/compomics/compomics-utilities\n",
      "Open issues with label \"help wanted\":\n",
      "\t- PTMFactory modifications loss (https://github.com/compomics/compomics-utilities/issues/24)\n",
      "\n",
      "\n",
      "Repo: claczny/VizBin\n",
      "Description: Repository of our application for human-augmented binning\n",
      "Language: Java\n",
      "URL: https://github.com/claczny/VizBin\n",
      "Open issues with label \"help wanted\":\n",
      "\t- MTJ-related loading warnings on Windows and Linux (https://github.com/claczny/VizBin/issues/10)\n",
      "\n",
      "\n",
      "Repo: compomics/searchgui\n",
      "Description: Highly adaptable common interface for proteomics search and de novo engines\n",
      "Language: Java\n",
      "URL: https://github.com/compomics/searchgui\n",
      "Open issues with label \"help wanted\":\n",
      "\t- Illegal reflective access (https://github.com/compomics/searchgui/issues/217)\n",
      "\t- FastaCLI  (https://github.com/compomics/searchgui/issues/212)\n",
      "\t- Resource path settings for conda version (https://github.com/compomics/searchgui/issues/211)\n",
      "\t- Progenesis + SearchGUI (https://github.com/compomics/searchgui/issues/208)\n",
      "\t- java.lang.IllegalArgumentException: Accession numbers cannot contain quotation marks: 'JNENNGHK_00049 4,4'-diaponeurosporenoate glycosyltransferase'! (https://github.com/compomics/searchgui/issues/206)\n",
      "\t- Andromeda Unhandled Exception (https://github.com/compomics/searchgui/issues/191)\n",
      "\t- (ana)conda install of searchgui broken on Win10 (https://github.com/compomics/searchgui/issues/188)\n",
      "\t- searchgui tide glibc error (https://github.com/compomics/searchgui/issues/182)\n",
      "\t- Simultaneous search of PTMs @ Residues AND @ Protein N-term (https://github.com/compomics/searchgui/issues/178)\n",
      "\t- andromeda search returns no output (https://github.com/compomics/searchgui/issues/155)\n",
      "\t- Memory issue (https://github.com/compomics/searchgui/issues/151)\n",
      "\t- Where can I define a new protease? (https://github.com/compomics/searchgui/issues/130)\n",
      "\t- Andromeda: unexpected results (https://github.com/compomics/searchgui/issues/99)\n",
      "\n",
      "\n",
      "Repo: mikessh/mageri\n",
      "Description: MAGERI - Assemble, align and call variants for targeted genome re-sequencing with unique molecular identifiers\n",
      "Language: Java\n",
      "URL: https://github.com/mikessh/mageri\n",
      "Open issues with label \"help wanted\":\n",
      "\t- Switch to new version of milib (https://github.com/mikessh/mageri/issues/10)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://api.github.com/search/repositories?q={}+{}&sort=stars&order=desc'.format(\n",
    "    '+'.join('topic:{}'.format(topic) for topic in topics), \n",
    "    '+'.join('language:{}'.format(language) for language in languages))\n",
    "repo_data = gh_curl_response(url, gh_username, gh_oauth_key)\n",
    "\n",
    "for repo in repo_data['items']:\n",
    "    repo_url = repo['url']\n",
    "    issues_url = '{}/issues?state=open&labels={}'.format(repo_url, issue_label.replace(' ', '%20'))\n",
    "    issue_data = gh_curl_response(issues_url, gh_username, gh_oauth_key)\n",
    "    if issue_data:\n",
    "        print('\\n')\n",
    "        print('Repo: {}'.format(repo['full_name']))\n",
    "        print('Description: {}'.format(repo['description']))\n",
    "        print('Language: {}'.format(repo['language']))\n",
    "        print('URL: {}'.format(repo['html_url']))\n",
    "        print('Open issues with label \"{}\":'.format(issue_label))\n",
    "        for issue in issue_data:\n",
    "            print('\\t- {} ({})'.format(issue['title'], issue['html_url']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-bioinformatics-help-wanted",
   "language": "python",
   "name": "env-bioinformatics-help-wanted"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
